
params {
    msconvert.do_demultiplex = false;       // whether or not to demultiplex with msconvert
    msconvert.do_simasspectra = true;       // whether or not to do simAsSpectra with msconvert
    msconvert.store_mzml = false;

    pdc_study_id = null
    n_raw_files = null

    ms_data_dir = '/home/ajm/code/nf-pdc/subset_mzML' // If null, all the raw files for the study through the PDC API.

    // general workflow params, can be changed
    result_dir = 'results/nf-pdc-dia' /** \type{str} Where results will be saved. */
    report_dir = 'reports/nf-pdc-dia' /** \type{str} Where results will be saved. */

    // default parameters for Encyclopedia searches, can be overridden by users
    // todo: follow up on these options: -quantifyAcrossSamples true -scoringBreadthType window
    encyclopedia.params = '-enableAdvancedOptions -v2scoring'
    encyclopedia.version = '3.0.0-SNAPSHOT'

    // fasta = 'https://panoramaweb.org/_webdav/MacCoss/Aaron/cromwell_tests/PDC000341/%40files/dbase/uniprot_human_jan2021_yeastENO1.fasta'
    fasta = '/home/ajm/code/nf-pdc/resources/uniprot_human_jan2021_yeastENO1_subset.fasta'

    // spectral_library = 'https://panoramaweb.org/_webdav/MacCoss/Aaron/cromwell_tests/PDC000341/%40files/dbase/pan_human_library.dlib'
    spectral_library = '/home/ajm/code/nf-pdc/resources/uniprot_human_jan2021_yeastENO1_subset-z3_nce33-prosit.dlib'

    // skyline_template_file = '/home/ajm/code/nf-pdc/nf-pdc/resources/template.sky.zip'
    skyline_template_file = 'https://panoramaweb.org/_webdav/MacCoss/Aaron/cromwell_tests/PDC000341/%40files/dbase/template_iRT.sky.zip'

    panorama.skyline_folder = null
    panorama.mzml_folder = null
    panorama.reports_folder = null

    skyline.save_intermediate_output = true

    qc_report.precursor_report_template = '/home/ajm/code/nf-pdc/nf-pdc/resources/precursor_quality.skyr'
    qc_report.replicate_report_template = '/home/ajm/code/nf-pdc/nf-pdc/resources/replicate_quality.skyr'
    qc_report.standard_proteins = ['iRT']

    s3_upload.bucket_name = null
    s3_upload.access_key = null
}

docker {
    enabled = true
}

/*
 * Set up secrets in the environment. 
 * Need to do it this way because Nextflow doesn't allow the use of secrets when running on AWS Batch
 */

// ensure PanoramaWeb API keys will work. see: https://github.com/nextflow-io/nextflow/issues/3690
env.PLACEHOLDER = "PLACEHOLDER_VALUE"

secret_value = nextflow.secret.SecretsLoader.instance.load().getSecret("PANORAMA_API_KEY")
secret_value = nextflow.secret.SecretsLoader.instance.load().getSecret("S3_SECRET_ACCESS_KEY")
if(secret_value) {
    env.PANORAMA_API_KEY = secret_value.value
    env.S3_SECRET_ACCESS_KEY = secret_value.value
}

aws {
    batch {
        // NOTE: this setting is only required if the AWS CLI tool is installed in a custom AMI
        cliPath = '/usr/local/aws-cli/v2/current/bin/aws'
        logsGroup = '/batch/tei-nextflow-batch'
        maxConnections = 20
        connectionTimeout = 10000
        uploadStorageClass = 'INTELLIGENT_TIERING'
        storageEncryption = 'AES256'
        retryMode = 'standard'
    }

    region = 'us-west-2'
}

// Execution Profiles
profiles {

    /*
     * Params for running pipeline on the local computer (e.g.:
     * your laptop). These can be overridden in the local config file.
     */
    standard {
        process.executor = 'local'

        // limit nextflow to running 1 task at a time
        executor.queueSize = 8

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '~/code/nf-pdc/mzml_cache'
        params.panorama_cache_directory = '~/code/nf-pdc/raw_cache'
    }
    aws {
        process.executor = 'awsbatch'
        process.queue = 'nextflow_basic_ec2'

        // params for running pipeline on aws batch
        // These can be overridden in local config file

        // max params allowed for your AWS Batch compute environment
        params.max_memory = '124.GB'
        params.max_cpus = 32
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = 's3://mc-tei-rex-nextflow-dda/dia/mzml_cache'
        params.panorama_cache_directory = 's3://mc-tei-rex-nextflow-dda/panorama_cache'
    }

    slurm {
        process.executor = 'slurm'

        params.max_memory = '12.GB'
        params.max_cpus = 8
        params.max_time = '240.h'

        // where to cache mzml files after running msconvert
        params.mzml_cache_directory = '/data/mass_spec/nextflow/nf-teirex-dia/mzml_cache'
        params.panorama_cache_directory = '/data/mass_spec/nextflow/panorama/raw_cache'
    }
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.report_dir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.report_dir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.report_dir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = false
    file    = "${params.report_dir}/pipeline_dag_${trace_timestamp}.html"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

